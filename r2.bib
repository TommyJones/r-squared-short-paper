@article{10.1016/j.spl.2020.108960, 
year = {2020}, 
title = {{On relationships between the Pearson and the distance correlation coefficients}}, 
author = {Edelmann, Dominic and Móri, Tamás F. and Székely, Gábor J.}, 
journal = {Statistics \& Probability Letters}, 
issn = {0167-7152}, 
doi = {10.1016/j.spl.2020.108960}, 
abstract = {{In this paper we show that for any fixed Pearson correlation coefficient strictly between − 1 and 1, the distance correlation coefficient can take any value in the open unit interval ( 0 , 1 ) .}}, 
pages = {108960}, 
volume = {169}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-16/1-s2.0-S0167715220302637-main.pdf}
}
@article{piepho2019, 
year = {2019}, 
title = {{A coefficient of determination ($R^2$) for generalized linear mixed models}}, 
author = {Piepho, Hans‐Peter}, 
journal = {Biometrical Journal}, 
issn = {0323-3847}, 
doi = {10.1002/bimj.201800270}, 
pmid = {30957911}, 
abstract = {{Extensions of linear models are very commonly used in the analysis of biological data. Whereas goodness of fit measures such as the coefficient of determination (R2) or the adjusted R2 are well established for linear models, it is not obvious how such measures should be defined for generalized linear and mixed models. There are by now several proposals but no consensus has yet emerged as to the best unified approach in these settings. In particular, it is an open question how to best account for heteroscedasticity and for covariance among observations present in residual error or induced by random effects. This paper proposes a new approach that addresses this issue and is universally applicable for arbitrary variance‐covariance structures including spatial models and repeated measures. It is exemplified using three biological examples.}}, 
pages = {860--872}, 
number = {4}, 
volume = {61}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-16/bimj.201800270.pdf}
}
@article{gelman2018r2, 
year = {2018}, 
title = {{R-squared for Bayesian Regression Models}}, 
author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki}, 
journal = {The American Statistician}, 
issn = {0003-1305}, 
doi = {10.1080/00031305.2018.1549100}, 
abstract = {{The usual definition of R2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the expected variance of the errors.}}, 
pages = {1--6}, 
number = {3}, 
volume = {73}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-16/R%20squared%20for%20Bayesian%20Regression%20Models.pdf}
}
@article{10.1080/00031305.2016.1256839, 
year = {2018}, 
title = {{A Coefficient of Determination for Generalized Linear Models}}, 
author = {Zhang, Dabao}, 
journal = {The American Statistician}, 
issn = {0003-1305}, 
doi = {10.1080/00031305.2016.1256839}, 
abstract = {{The coefficient of determination, a.k.a. R2, is well-defined in linear regression models, and measures the proportion of variation in the dependent variable explained by the predictors included in the model. To extend it for generalized linear models, we use the variance function to define the total variation of the dependent variable, as well as the remaining variation of the dependent variable after modeling the predictive effects of the independent variables. Unlike other definitions that demand complete specification of the likelihood function, our definition of R2 only needs to know the mean and variance functions, so applicable to more general quasi-models. It is consistent with the classical measure of uncertainty using variance, and reduces to the classical definition of the coefficient of determination when linear regression models are considered.}}, 
pages = {310--316}, 
number = {4}, 
volume = {71}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-16/A%20Coefficient%20of%20Determination%20for%20Generalized%20Linear%20Models.pdf}
}
@article{undefined, 
year = {2016}, 
title = {{An Analysis of Deep Neural Network Models for Practical Applications}}, 
author = {Canziani, Alfredo and Culurciello, Eugenio and Paszke, Adam}, 
journal = {arXiv}, 
eprint = {1605.07678}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-26/1605.07678.pdf}
}
@article{10.1016/j.jspi.2010.01.008, 
year = {2010}, 
title = {{A robust coefficient of determination for regression}}, 
author = {Renaud, Olivier and Victoria-Feser, Maria-Pia}, 
journal = {Journal of Statistical Planning and Inference}, 
issn = {0378-3758}, 
doi = {10.1016/j.jspi.2010.01.008}, 
abstract = {{To assess the quality of the fit in a multiple linear regression, the coefficient of determination or R2 is a very simple tool, yet the most used by practitioners. Indeed, it is reported in most statistical analyzes, and although it is not recommended as a final model selection tool, it provides an indication of the suitability of the chosen explanatory variables in predicting the response. In the classical setting, it is well known that the least-squares fit and coefficient of determination can be arbitrary and/or misleading in the presence of a single outlier. In many applied settings, the assumption of normality of the errors and the absence of outliers are difficult to establish. In these cases, robust procedures for estimation and inference in linear regression are available and provide a suitable alternative.In this paper we present a companion robust coefficient of determination that has several desirable properties not shared by others. It is robust to deviations from the specified regression model (like the presence of outliers), it is efficient if the errors are normally distributed, it does not make any assumption on the distribution of the explanatory variables (and therefore no assumption on the unconditional distribution of the responses). We also show that it is a consistent estimator of the population coefficient of determination. A simulation study and two real datasets support the appropriateness of this estimator, compared with classical (least-squares) and several previously proposed robust R2, even for small sample sizes.}}, 
pages = {1852--1862}, 
number = {7}, 
volume = {140}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-16/1-s2.0-S0378375810000194-main.pdf}
}
@article{hu2006, 
year = {2006}, 
title = {{Properties of $R^2$ statistics for logistic regression}}, 
author = {Hu, Bo and Palta, Mari and Shao, Jun}, 
journal = {Statistics in Medicine}, 
issn = {1097-0258}, 
doi = {10.1002/sim.2300}, 
pmid = {16059870}, 
abstract = {{Various R2 statistics have been proposed for logistic regression to quantify the extent to which the binary response can be predicted by a given logistic regression model and covariates. We study the asymptotic properties of three popular variance-based R2 statistics. We find that two variance-based R2 statistics, the sum of squares and the squared Pearson correlation, have identical asymptotic distribution whereas the third one, Gini's concentration measure, has a different asymptotic behaviour and may overstate the predictivity of the model and covariates when the model is misspecified. Our result not only provides a theoretical basis for the findings in previous empirical and numerical work, but also leads to asymptotic confidence intervals. Statistical variability can then be taken into account when assessing the predictive value of a logistic regression model. Copyright © 2005 John Wiley \& Sons, Ltd.}}, 
pages = {1383--1395}, 
number = {8}, 
volume = {25}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-19/sim.2300.pdf}
}
@article{windmeijer1997, 
year = {1997}, 
title = {{An R-squared measure of goodness of fit for some common nonlinear regression models}}, 
author = {Cameron, A. Colin and Windmeijer, Frank A.G.}, 
journal = {Journal of Econometrics}, 
issn = {0304-4076}, 
doi = {10.1016/s0304-4076(96)01818-0}, 
abstract = {{For regression models other than the linear model, R-squared type goodness-of-fit summary statistics have been constructed for particular models using a variety of methods. We propose an R-squared measure of goodness of fit for the class of exponential family regression models, which includes logit, probit, Poisson, geometric, gamma, and exponential. This R-squared is defined as the proportionate reduction in uncertainty, measured by Kullback-Leibler divergence, due to the inclusion of regressors. Under further conditions concerning the conditional mean function it can also be interpreted as the fraction of uncertainty explained by the fitted model.}}, 
pages = {329--342}, 
number = {2}, 
volume = {77}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-30/10.1.1.926.4747.pdf}
}
@book{neter1996applied, 
year = {1996}, 
title = {{Applied Linear Statistical Models}}, 
author = {Neter, John and Kutner, Michael H and Nachtsheim, Christopher J and Wasserman, William}, 
publisher = {Irwin Chicago}
}
@incollection{barten1987, 
year = {1987}, 
title = {{The Coeffecient of Determination for Regression without a Constant Term}}, 
author = {Barten, Anton P.}, 
editor = {R., Heijmans and H., Neudecker}, 
booktitle = {The Practice of Econometrics}, 
isbn = {978-94-009-3591-4}, 
pages = {187---189}, 
volume = {15}, 
series = {International Studies in Economics and Econometrics}, 
publisher = {Springer, Dordrecht}, 
doi = {10.1007/978-94-009-3591-4\_12}
}
@article{helland1987, 
year = {1987}, 
title = {{On the Interpretation and Use of $R^2$ in Regression Analysis}}, 
author = {Helland, Inge S.}, 
journal = {International Biometric Society}, 
pages = {61---69}, 
number = {1}, 
volume = {43}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-19/2531949.pdf}
}
@article{kvalseth1985, 
year = {1985}, 
title = {{Cautionary Note about $R^2$}}, 
author = {Kvalseth, Tarald O.}, 
journal = {The American Statistician}, 
pages = {297---285}, 
number = {4}, 
volume = {39}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-30/2683704.pdf}
}
@book{mcfadden1977, 
year = {1977}, 
title = {{An Application of Diagnostic Tests for the Independence From Irrelevant Alternatives Property of the Multinomial Logit Model}}, 
author = {McFadden, Daniel and Train, Kenneth}, 
isbn = {0309026644}, 
series = {Forecasting passenger and freight travel}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-16/637-007.pdf}
}
@article{barrett1974, 
year = {1974}, 
title = {{The Coefficient of Determination-Some Limitations}}, 
author = {Barrett, James P.}, 
journal = {The American Statistician}, 
url = {https://www.jstor.org/stable/2683523}, 
pages = {19--20}, 
number = {1}, 
volume = {28}, 
local-url = {file://localhost/Users/tommy/Google%20Drive/gmu/_dissertation/references/2021-01-16/2683523.pdf}
}